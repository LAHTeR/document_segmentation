{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"MIG-08137aa2-e69b-5e74-8390-7997329b1336\"\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and convert data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing documents:   0%|          | 0/5 [00:00<?, ?doc/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping row with inventory number 1171 due to status message: 'Niet gedigitaliseerd.'\n",
      "Skipping row with inventory number 2770 due to status message: 'Niet gedigitaliseerd.'\n",
      "Skipping row with inventory number 2770 due to status message: 'Niet gedigitaliseerd.'\n",
      "Skipping row with inventory number 2770 due to status message: 'Niet gedigitaliseerd.'\n",
      "Skipping row with inventory number 2911 due to status message: 'Niet gedigitaliseerd.'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "from document_segmentation.pagexml.generale_missiven import GeneraleMissiven\n",
    "from document_segmentation.settings import (\n",
    "    GENERALE_MISSIVEN_DOCUMENT_DIR,\n",
    "    GENERALE_MISSIVEN_SHEET,\n",
    ")\n",
    "\n",
    "N = None\n",
    "\n",
    "GENERALE_MISSIVEN_DOCUMENT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "sheet = GeneraleMissiven(GENERALE_MISSIVEN_SHEET)\n",
    "\n",
    "existing_docs = {\n",
    "    path.stem\n",
    "    for path in GENERALE_MISSIVEN_DOCUMENT_DIR.glob(\"*.json\")\n",
    "    if path.is_file()\n",
    "}\n",
    "\n",
    "for document in tqdm(\n",
    "    sheet.to_documents(n=N, skip_ids=existing_docs),\n",
    "    total=(N or len(sheet)) - len(existing_docs),\n",
    "    desc=\"Writing documents\",\n",
    "    unit=\"doc\",\n",
    "):\n",
    "    document_file = GENERALE_MISSIVEN_DOCUMENT_DIR / f\"{document.id}.json\"\n",
    "\n",
    "    with document_file.open(\"xt\") as f:\n",
    "        f.write(document.model_dump_json())\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_DATA = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading JSON files:  19%|█▉        | 175/909 [00:12<00:47, 15.53file/s]WARNING:root:No pages found in document id='354' inventory_nr=1684 inventory_part=None pages=[].\n",
      "Reading JSON files:  35%|███▍      | 314/909 [00:21<00:35, 16.86file/s]WARNING:root:No pages found in document id='353' inventory_nr=1684 inventory_part=None pages=[].\n",
      "Reading JSON files:  38%|███▊      | 346/909 [00:21<00:14, 38.30file/s]WARNING:root:No pages found in document id='352' inventory_nr=1684 inventory_part=None pages=[].\n",
      "Reading JSON files:  58%|█████▊    | 528/909 [00:35<00:16, 22.41file/s]WARNING:root:No pages found in document id='412' inventory_nr=1887 inventory_part=None pages=[].\n",
      "Reading JSON files: 100%|██████████| 909/909 [01:07<00:00, 13.44file/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "191146"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from document_segmentation.model.dataset import PageDataset\n",
    "from document_segmentation.settings import MIN_REGION_TEXT_LENGTH\n",
    "\n",
    "dataset = (\n",
    "    PageDataset.from_dir(GENERALE_MISSIVEN_DOCUMENT_DIR)\n",
    "    .remove_short_regions(MIN_REGION_TEXT_LENGTH)\n",
    "    .shuffle()\n",
    ")\n",
    "# TODO: move region filtering to training/classification step?\n",
    "\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({<Label.IN: 2>: 189343, <Label.BEGIN: 1>: 905, <Label.END: 3>: 898})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset._class_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[210.97792494481237, 1.0095170694608755, 212.6206896551724, 191146.0]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.class_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Page(label=<Label.IN: 2>, regions=[Region(id='region_c50d90ce-7c08-4c50-b52c-0f17352866c8_2', types=(<RegionType.PARAGRAPH: 'paragraph'>, <RegionType.PHYSICAL_STRUCTURE_DOC: 'physical_structure_doc'>, <RegionType.TEXT_REGION: 'text_region'>, <RegionType.PAGEXML_DOC: 'pagexml_doc'>), coordinates=((657, 1139), (645, 1160), (648, 1178), (690, 1196), (750, 1205), (756, 1211), (747, 1233), (732, 1242), (657, 1263), (603, 1272), (566, 1296), (560, 1317), (587, 1329), (618, 1326), (747, 1341), (783, 1353), (801, 1374), (789, 1401), (762, 1419), (771, 1447), (765, 1489), (750, 1525), (726, 1558), (741, 1567), (753, 1585), (726, 1636), (717, 1670), (717, 1724), (726, 1745), (723, 1838), (747, 1905), (759, 1995), (759, 2164), (777, 2248), (783, 2354), (789, 2375), (789, 2471), (798, 2489), (816, 2498), (925, 2492), (1030, 2501), (1085, 2498), (1145, 2507), (1449, 2507), (1530, 2531), (1567, 2531), (1624, 2513), (1762, 2495), (1829, 2498), (2181, 2489), (2422, 2498), (2443, 2489), (2458, 2474), (2467, 2417), (2467, 2345), (2482, 2287), (2479, 2194), (2491, 2158), (2485, 2125), (2488, 2073), (2479, 2040), (2498, 2004), (2498, 1974), (2479, 1902), (2482, 1811), (2488, 1787), (2488, 1697), (2470, 1624), (2473, 1558), (2467, 1543), (2473, 1431), (2488, 1317), (2498, 1296), (2498, 1266), (2470, 1230), (2455, 1224), (2416, 1224), (2347, 1239), (2169, 1239), (2037, 1227), (1781, 1233), (1491, 1227), (1437, 1208), (1452, 1196), (1570, 1172), (1648, 1163), (1687, 1127), (1684, 1115), (1666, 1106), (1567, 1106), (1494, 1121), (1341, 1121), (1256, 1112), (1021, 1115), (934, 1106), (880, 1118), (838, 1136), (810, 1112), (747, 1100), (699, 1112)), lines=('De verpachting der', '§ 164', 'Jaccatrasche Domainem is voor dit Ja a 1793, op den', 'in admodiatio 31 december 1792 publiek geschied, alleen uijt', '„gezondert de Pachten van de Phoen Thopo„', 'Chineesche Taptafels, de maijang, de maag', 'en de groente kraamen en winkels, die weeder', 'naar Jaarlijkse gewoonte aan de Luijtenants', 'der Chineesen, mitsgaders de Chineesche lee', '„den van het Collegie van Boedel meesteren', 'in admodiatie zijn afgestaan geworden,')), Region(id='region_2f02a6e5-3c4a-4916-b04d-ef056ed2fb4a_1', types=(<RegionType.PARAGRAPH: 'paragraph'>, <RegionType.PHYSICAL_STRUCTURE_DOC: 'physical_structure_doc'>, <RegionType.TEXT_REGION: 'text_region'>, <RegionType.PAGEXML_DOC: 'pagexml_doc'>), coordinates=((2461, 2703), (2440, 2682), (2401, 2682), (2389, 2688), (2332, 2697), (2226, 2697), (2220, 2700), (2217, 2697), (2034, 2694), (1970, 2706), (1871, 2706), (1868, 2709), (1723, 2706), (1720, 2709), (1479, 2712), (1476, 2715), (1039, 2709), (1036, 2706), (991, 2706), (925, 2694), (865, 2694), (862, 2691), (850, 2694), (759, 2691), (735, 2700), (717, 2700), (699, 2706), (684, 2718), (675, 2742), (675, 2757), (690, 2779), (726, 2788), (795, 2794), (816, 2803), (828, 2815), (819, 2839), (804, 2854), (741, 2881), (762, 2905), (771, 2923), (774, 2956), (771, 2968), (792, 3008), (801, 3035), (801, 3083), (795, 3101), (810, 3116), (807, 3125), (786, 3149), (786, 3161), (774, 3185), (774, 3200), (768, 3212), (762, 3249), (744, 3291), (750, 3372), (786, 3469), (789, 3526), (804, 3541), (822, 3547), (982, 3544), (985, 3541), (1124, 3544), (1163, 3538), (1796, 3544), (1916, 3526), (2019, 3529), (2022, 3532), (2085, 3529), (2130, 3535), (2196, 3532), (2232, 3538), (2260, 3535), (2296, 3541), (2356, 3541), (2389, 3550), (2422, 3547), (2479, 3550), (2498, 3544), (2513, 3523), (2507, 3324), (2504, 3321), (2504, 3270), (2488, 3185), (2482, 3038), (2476, 3008), (2479, 2881), (2464, 2821), (2467, 2724)), lines=('§ 165 dit onse Resolutien van den 19 Junij 1792.', 'resert tot de waar uit wij een Extract neevens deeze', '„jo ens de cerije voegen, blijkt, dat wij op die vach, van den in', '„dischien handel in Cormandelsche surat', '„sche en Bengaalsche Lywaten, die de Comp', 'aan zich gereserveerd heeft gehad, af gesien'))], scan_nr=2565, doc_id='NL-HaNA_1.04.02_3970_2565.jpg')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = int(len(dataset) * TRAINING_DATA)\n",
    "\n",
    "training_data = dataset[:split]\n",
    "test_data = dataset[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({<Label.IN: 2>: 151475, <Label.BEGIN: 1>: 726, <Label.END: 3>: 715})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data._class_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "# WEIGHTS = torch.Tensor(dataset.class_weights())   # For an imbalanced dataset\n",
    "WEIGHTS = None  # For a balanced dataset\n",
    "\n",
    "TRAINING_DATA_MAX = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "726"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from document_segmentation.pagexml.datamodel.label import Label\n",
    "\n",
    "sample_size = training_data._class_counts()[Label.BEGIN]\n",
    "sample_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carstenschnober/LAHTeR/workspace/document-segmentation/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PageClassifier(\n",
       "  (_embedding): PageEmbedding(\n",
       "    (_region_model): RegionEmbedding(\n",
       "      (_transformer_model): RobertaModel(\n",
       "        (embeddings): RobertaEmbeddings(\n",
       "          (word_embeddings): Embedding(42774, 768, padding_idx=1)\n",
       "          (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "          (token_type_embeddings): Embedding(1, 768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder): RobertaEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-11): 12 x RobertaLayer(\n",
       "              (attention): RobertaAttention(\n",
       "                (self): RobertaSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): RobertaSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): RobertaIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): RobertaOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (pooler): RobertaPooler(\n",
       "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (activation): Tanh()\n",
       "        )\n",
       "      )\n",
       "      (_region_type): Embedding(9, 16)\n",
       "      (_linear): Linear(in_features=784, out_features=4, bias=True)\n",
       "    )\n",
       "    (_rnn): LSTM(4, 128, batch_first=True, dropout=0.1, bidirectional=True)\n",
       "    (_linear): Linear(in_features=256, out_features=64, bias=True)\n",
       "  )\n",
       "  (_linear): Linear(in_features=64, out_features=4, bias=True)\n",
       "  (_softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from document_segmentation.model.page_classifier import PageClassifier\n",
    "\n",
    "model = PageClassifier()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mps'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "454.147705078125\n"
     ]
    }
   ],
   "source": [
    "if model._device == \"mps\":\n",
    "    torch.mps.empty_cache()\n",
    "    print(torch.mps.current_allocated_memory() / 1024**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 67/67.71875 [03:29<00:02,  3.19s/batch]/Users/carstenschnober/LAHTeR/workspace/document-segmentation/.venv/lib/python3.11/site-packages/tqdm/std.py:636: TqdmWarning: clamping frac to range [0, 1]\n",
      "  full_bar = Bar(frac,\n",
      "100%|██████████| 68/67.71875 [03:31<00:00,  3.11s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current allocated memory (MPS): 13141 MB\n",
      "Driver allocated memory (MPS): 14500 MB\n",
      "[Loss:\t1.158]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/67.71875 [00:06<00:00, 11.22batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current allocated memory (MPS): 13141 MB\n",
      "Driver allocated memory (MPS): 14366 MB\n",
      "[Loss:\t1.068]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/67.71875 [00:06<00:00, 10.06batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current allocated memory (MPS): 13141 MB\n",
      "Driver allocated memory (MPS): 14366 MB\n",
      "[Loss:\t0.989]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/67.71875 [00:07<00:00,  9.37batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current allocated memory (MPS): 13141 MB\n",
      "Driver allocated memory (MPS): 14366 MB\n",
      "[Loss:\t0.890]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/67.71875 [00:07<00:00,  9.06batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current allocated memory (MPS): 13141 MB\n",
      "Driver allocated memory (MPS): 14366 MB\n",
      "[Loss:\t0.988]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/67.71875 [00:07<00:00,  8.91batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current allocated memory (MPS): 13141 MB\n",
      "Driver allocated memory (MPS): 14366 MB\n",
      "[Loss:\t0.912]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/67.71875 [00:07<00:00,  8.68batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current allocated memory (MPS): 13141 MB\n",
      "Driver allocated memory (MPS): 14366 MB\n",
      "[Loss:\t0.858]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/67.71875 [00:07<00:00,  8.88batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current allocated memory (MPS): 13141 MB\n",
      "Driver allocated memory (MPS): 14366 MB\n",
      "[Loss:\t0.848]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/67.71875 [00:07<00:00,  9.04batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current allocated memory (MPS): 13141 MB\n",
      "Driver allocated memory (MPS): 14366 MB\n",
      "[Loss:\t0.893]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/67.71875 [00:07<00:00,  8.86batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current allocated memory (MPS): 13141 MB\n",
      "Driver allocated memory (MPS): 14366 MB\n",
      "[Loss:\t0.871]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.train_(training_data.balance(sample_size).shuffle(), EPOCHS, BATCH_SIZE, WEIGHTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted\tActual\tPage ID\tText\tScores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1194.6875 [00:04<1:37:33,  4.90s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END\tIN\tNL-HaNA_1.04.02_3712_0150.jpg\tde waarde, van het voorwerp der bescher„; ming, de\t[5.863048045284813e-06, 0.059085000306367874, 0.9409074783325195, 1.673855308581551e-06]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/1194.6875 [00:08<1:23:57,  4.22s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEGIN\tBEGIN\tNL-HaNA_1.04.02_1082_0287.jpg\tHet onse brieven vanden 28en december, 1623: p d'e\t[0.9999990463256836, 7.214325705717783e-07, 2.554999980475259e-07, 6.420295961540035e-10]\n",
      "END\tIN\tNL-HaNA_1.04.02_1816_0337.jpg\toff men haer behoorl: rang wel; soude observeren, \t[3.417672996874899e-05, 0.007159017026424408, 0.9922771453857422, 0.0005295872106216848]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/1194.6875 [00:11<1:13:10,  3.68s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END\tIN\tNL-HaNA_1.04.02_1903_0454.jpg\t\t[0.03907805681228638, 0.013840816915035248, 0.9424195885658264, 0.00466154795140028]\n",
      "BEGIN\tIN\tNL-HaNA_1.04.02_1245_0250.jpg\tOp dat dese retourvloot uEd=e in goede ordre; mogt\t[0.9870861172676086, 0.0036741276271641254, 0.009190519340336323, 4.927271947963163e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/1194.6875 [00:14<1:09:47,  3.52s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END\tIN\tNL-HaNA_1.04.02_3712_0153.jpg\t\t[0.03907805681228638, 0.013840816915035248, 0.9424195885658264, 0.00466154795140028]\n",
      "END\tIN\tNL-HaNA_1.04.02_3679_0410.jpg\tDen Gezaghebber te Gale Cornelis Dionijsius Kraije\t[8.100091690721456e-07, 8.468030898711731e-08, 0.9999972581863403, 1.7733493677951628e-06]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/1194.6875 [00:17<1:06:13,  3.34s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END\tIN\tNL-HaNA_1.04.02_1490_0262.jpg\twelk gunst bewijs, indien het van u Ed:e hoog agtb\t[0.0014739584876224399, 0.0013731232611462474, 0.996614396572113, 0.0005385656841099262]\n",
      "BEGIN\tIN\tNL-HaNA_1.04.02_1573_0600.jpg\ttegens den schipper Cornelis de mees; terwwegens v\t[0.9999935626983643, 4.349090431787772e-06, 2.059779490082292e-06, 7.405255519898901e-09]\n",
      "END\tIN\tNL-HaNA_1.04.02_1179B_0237.jpg\tcoopmanschappen noch voor het merendeel bij de; pa\t[3.255553338021855e-08, 1.4746814880339798e-09, 0.9999998807907104, 1.6942381364515313e-07]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6/1194.6875 [00:21<1:04:03,  3.23s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEGIN\tIN\tNL-HaNA_1.04.02_2484_0192.jpg\tder onkost reecq: van de gem: vier scheepen; Concs\t[0.9930364489555359, 0.005756630562245846, 0.0011777796316891909, 2.9128355890861712e-05]\n",
      "BEGIN\tIN\tNL-HaNA_1.04.02_3873_0415.jpg\tgehad, wel te ontvangen uwelEd: Hoog Achte; nadere\t[0.9999688863754272, 2.7408536880102474e-06, 2.8330739951343276e-05, 2.241546681602813e-08]\n",
      "BEGIN\tIN\tNL-HaNA_1.04.02_2392_0593.jpg\tjongste eerbiedige missive van den 2:' april; dese\t[0.9995936751365662, 0.00013383489567786455, 0.00027110264636576176, 1.370459358440712e-06]\n",
      "BEGIN\tIN\tNL-HaNA_1.04.02_1862_0268.jpg\tN:o 24: Nog nader vervolg van het acteboek der ver\t[0.999860405921936, 4.682922372012399e-05, 9.252452582586557e-05, 2.2423694190365495e-07]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 7/1194.6875 [00:24<1:03:43,  3.22s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END\tEND\tNL-HaNA_1.04.02_3713_0365.jpg\tDog dat ten agteren staan of blijven; Zeeland. . .\t[1.1244992492720485e-08, 2.129478399170992e-10, 1.0, 3.673353887734265e-08]\n",
      "END\tIN\tNL-HaNA_1.04.02_2636_0773.jpg\tMallabaar 455. Persoonen Per Transport; Inlandse d\t[3.972269951191265e-06, 1.0484299309609924e-05, 0.9999349117279053, 5.0627415475901216e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 8/1194.6875 [00:26<1:00:52,  3.08s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END\tEND\tNL-HaNA_1.04.02_7529_0897.jpg\tSoo hebben wy goedt gevonden; desen te sluyten ond\t[2.494989814749715e-07, 5.397574609489197e-10, 0.9999997615814209, 4.7795559510177554e-08]\n",
      "END\tIN\tNL-HaNA_1.04.02_7588_0232.jpg\t\t[0.007511676289141178, 0.001985306851565838, 0.9891741275787354, 0.001328896265476942]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 9/1194.6875 [00:30<1:04:07,  3.25s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEGIN\tIN\tNL-HaNA_1.04.02_2419_1110.jpg\tsittinge van den 22.:' aug:s J:o lee„; den ingevol\t[0.9999793767929077, 9.000498721434269e-06, 1.1554059710761067e-05, 2.7266107593959532e-08]\n",
      "BEGIN\tIN\tNL-HaNA_1.04.02_1086_0088.jpg\tvan Volck versien, soo dat sonder ander ontseth; q\t[0.9999980926513672, 1.1456986612756737e-06, 6.870217248433619e-07, 1.2852175990119008e-09]\n",
      "END\tIN\tNL-HaNA_1.04.02_3251_1535.jpg\thet meeste respect,; Wel-Edele, Hoog Agtbare, wijz\t[4.195796154959908e-09, 8.19595780132687e-12, 1.0, 3.168572959566518e-09]\n",
      "BEGIN\tIN\tNL-HaNA_1.04.02_3945_1181.jpg\tBij onze eerbiedige van den 40 Julij deeses; Iaars\t[0.999995231628418, 3.7799568417540286e-06, 9.186329066324106e-07, 4.108411832959291e-09]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1194.6875 [00:33<1:03:52,  3.23s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEGIN\tIN\tNL-HaNA_1.04.02_1934_0078.jpg\ttwee predicanten; als Iohannes wen„; „ting en phil\t[0.9432636499404907, 0.05347616225481033, 0.0031261183321475983, 0.00013402526383288205]\n",
      "BEGIN\tBEGIN\tNL-HaNA_1.04.02_3187_0039.jpg\tDe Heer Thomas Hope; Representant Van zijn Doorlug\t[0.9999914169311523, 3.0535361474903766e-06, 5.432278612715891e-06, 1.1481344763808465e-08]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 11/1194.6875 [00:37<1:08:08,  3.45s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEGIN\tIN\tNL-HaNA_1.04.02_2422_0585.jpg\tPersia ons laeste schrijvens aen uwel Ed=le; hoog \t[0.9929220676422119, 0.003058923641219735, 0.0039904313161969185, 2.8508415198302828e-05]\n",
      "END\tEND\tNL-HaNA_1.04.02_1075_0454.jpg\tdie wij voor seecker houden dar becomen sullen, ti\t[4.2141778067161795e-06, 2.7674774173647165e-05, 0.9999048709869385, 6.333187775453553e-05]\n",
      "BEGIN\tIN\tNL-HaNA_1.04.02_1147_0014.jpg\tvan Julij passato gecombineert de havenen onser ha\t[0.9998660087585449, 7.65245349612087e-05, 5.714639701182023e-05, 3.3674626820356934e-07]\n",
      "END\tIN\tNL-HaNA_1.04.02_1802_0173.jpg\tBatavia van wien wij onder dato 30:e 9ber: 1711.; \t[0.0004409916582517326, 0.45363715291023254, 0.5430079698562622, 0.002913794247433543]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 12/1194.6875 [00:40<1:03:59,  3.25s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEGIN\tIN\tNL-HaNA_1.04.02_3530_0307.jpg\twij sullen over den inhoud van het een; en ander b\t[0.8414695858955383, 0.0007727883639745414, 0.15766596794128418, 9.158164175460115e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 13/1194.6875 [00:43<1:04:20,  3.27s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEGIN\tIN\tNL-HaNA_1.04.02_7587_1016.jpg\tgem. Visitateur der soloien bevoolen; te sorgen, d\t[0.9697682857513428, 0.029365550726652145, 0.0008244561031460762, 4.164839265285991e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 14/1194.6875 [00:46<1:02:00,  3.15s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END\tIN\tNL-HaNA_1.04.02_2452_0172.jpg\tRagia; groot vader den ouden; Singa /:bij zijne on\t[2.0926111119479174e-06, 1.9411938865232514e-06, 0.9999781847000122, 1.7730120816850103e-05]\n",
      "BEGIN\tBEGIN\tNL-HaNA_1.04.02_1245_1119.jpg\tMette schepen walcheren, oijevaer en Diemermeer; v\t[0.770165205001831, 0.1885010004043579, 0.040057774633169174, 0.0012759632663801312]\n",
      "END\tEND\tNL-HaNA_1.04.02_3819_0519.jpg\tHoogagting in respect,; WelEdele Hoog Agtbare Wijz\t[2.398023113414638e-08, 4.165540135048218e-10, 0.9999998807907104, 6.99478661658759e-08]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 15/1194.6875 [00:49<1:00:33,  3.08s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END\tIN\tNL-HaNA_1.04.02_3339_0414.jpg\thoogsten benoodigt opgegeeven hebben, en wij Uw we\t[0.0006963554187677801, 0.40175408124923706, 0.5939170718193054, 0.0036324812099337578]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 16/1194.6875 [00:52<1:00:02,  3.06s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END\tIN\tNL-HaNA_1.04.02_2971_0383.jpg\t\t[0.03907805681228638, 0.013840816915035248, 0.9424195885658264, 0.00466154795140028]\n",
      "BEGIN\tIN\tNL-HaNA_1.04.02_2753_0054.jpg\tparadicins derhalven dat 't UE wel Edele; de Gener\t[0.9827498197555542, 0.003498725825920701, 0.013699306175112724, 5.222002073423937e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 17/1194.6875 [00:55<59:41,  3.04s/batch]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END\tIN\tNL-HaNA_1.04.02_2450_0117.jpg\tAan sijn Hoog Edelheijt den; wel Edele Gestrenge H\t[0.0001243518927367404, 1.1170465441523447e-08, 0.9998754262924194, 1.911695903800137e-07]\n",
      "END\tIN\tNL-HaNA_1.04.02_1441_0851.jpg\tBatavia Hoog Ed. s goedvinden zal konnen zijn; -; \t[0.0005416481872089207, 0.00028018560260534286, 0.9989012479782104, 0.000276892795227468]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 18/1194.6875 [00:58<1:00:16,  3.07s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEGIN\tIN\tNL-HaNA_1.04.02_3218_0414.jpg\tman geniet, behoudens hare presente; rang Dat verm\t[0.9596244692802429, 0.002514767227694392, 0.037762343883514404, 9.833381045609713e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 19/1194.6875 [01:02<1:01:33,  3.14s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEGIN\tBEGIN\tNL-HaNA_1.04.02_2018_0041.jpg\tAan d' Edele Hoog agtb: Heeren; Bewinthebberen Ter\t[0.9999982118606567, 1.2388182994982344e-06, 5.722354217141401e-07, 1.6351472398312694e-09]\n",
      "END\tIN\tNL-HaNA_1.04.02_1613_0251.jpg\twij hebben na Sirrelon geordonneerd te; besorgen, \t[4.013634580246617e-08, 6.068252123014872e-09, 0.9999995231628418, 4.717089439054689e-07]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 20/1194.6875 [01:05<1:01:28,  3.14s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END\tIN\tNL-HaNA_1.04.02_1251_0383.jpg\tWij sullen daerop nu te meer acht geven, ende op't\t[0.0006341387052088976, 0.0049803960137069225, 0.9931138157844543, 0.0012716982746496797]\n",
      "BEGIN\tIN\tNL-HaNA_1.04.02_3338_0456.jpg\tVoor de Kamer Hoorn.; de Jonkvrouwe Maria Jacoba, \t[0.9999881982803345, 6.5898643697437365e-06, 5.241326107352506e-06, 1.9200708578637204e-08]\n",
      "END\tIN\tNL-HaNA_1.04.02_2019_0289.jpg\tSumat:s W„t Cust; den Coopman; Arend van Broyel; t\t[0.06965924054384232, 0.05153330788016319, 0.8749170303344727, 0.0038904959801584482]\n",
      "IN\tBEGIN\tNL-HaNA_1.04.02_1208_0013.jpg\tvoorleden say soen hebben wij u Eed e toe„; gesond\t[0.0005803724634461105, 0.9990234375, 0.0002538298722356558, 0.00014233555702958256]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 21/1194.6875 [01:08<1:02:48,  3.21s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEGIN\tIN\tNL-HaNA_1.04.02_3530_0321.jpg\t§ 191. De Dankbaarheid is bestemd tot; een Contra \t[0.961074709892273, 0.038403864949941635, 0.0004944694810546935, 2.6902678655460477e-05]\n",
      "END\tIN\tNL-HaNA_1.04.02_1261_0210.jpg\tgetelt, omme in 't vaderlandt aen haer ofte haere;\t[0.0012635620078071952, 2.4761845907050883e-07, 0.9987348914146423, 1.264903858100297e-06]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 23/1194.6875 [01:16<1:06:32,  3.41s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END\tIN\tNL-HaNA_1.04.02_2657_0140.jpg\t\t[0.03907805681228638, 0.013840816915035248, 0.9424195885658264, 0.00466154795140028]\n",
      "END\tIN\tNL-HaNA_1.04.02_2145_0110.jpg\t\t[0.03907805681228638, 0.013840816915035248, 0.9424195885658264, 0.00466154795140028]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 24/1194.6875 [01:19<1:04:29,  3.31s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END\tIN\tNL-HaNA_1.04.02_1859_1092.jpg\tnevens desen gaat tot uw Ed: Hoog agtb:; onsen Eij\t[0.0014979689149186015, 5.993101149215363e-05, 0.9983595013618469, 8.254900603787974e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 25/1194.6875 [01:21<1:01:14,  3.14s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEGIN\tIN\tNL-HaNA_1.04.02_7533_0358.jpg\trieden van verschooning wegens het lang aenhouden;\t[0.9688984155654907, 0.02999374270439148, 0.001067204400897026, 4.068030830239877e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 26/1194.6875 [01:24<59:28,  3.05s/batch]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END\tIN\tNL-HaNA_1.04.02_2150_0276.jpg\t\t[0.007511676289141178, 0.001985306851565838, 0.9891741275787354, 0.001328896265476942]\n",
      "END\tIN\tNL-HaNA_1.04.02_3679_0216.jpg\tIavas N=t P=t C=t tezenden, van de swaarste en Gaa\t[2.903817585320212e-05, 0.0003144772199448198, 0.9993720650672913, 0.0002844264090526849]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 27/1194.6875 [01:28<1:03:12,  3.25s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEGIN\tIN\tNL-HaNA_1.04.02_1234_0396.jpg\tover laten gaen, ende devoir doen, dat bij provisi\t[0.9997461438179016, 0.00012616081221494824, 0.00012688440619967878, 7.096328431543952e-07]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 29/1194.6875 [01:34<59:28,  3.06s/batch]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END\tEND\tNL-HaNA_1.04.02_1134_0047.jpg\ttot voorigen florisanten standt laeten comen, ons \t[8.782621080172248e-06, 0.00014797977928537875, 0.9997205138206482, 0.00012269943545106798]\n",
      "BEGIN\tIN\tNL-HaNA_1.04.02_3914_0166.jpg\tuit dien hoofde, dat wij uwelEdele Hoog Achtb; ver\t[0.9982395172119141, 0.0016130213625729084, 0.00014673433906864375, 7.31905231532437e-07]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 30/1194.6875 [01:37<1:00:19,  3.11s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEGIN\tIN\tNL-HaNA_1.04.02_1238_0459.jpg\tweder te rugh gecomen de Commandeur; ijsbrandt God\t[0.9905852675437927, 0.004420632496476173, 0.004910458344966173, 8.366243855562061e-05]\n",
      "END\tIN\tNL-HaNA_1.04.02_7536_0295.jpg\top vervolgens schriftelijk berigt is; het daer op \t[0.00012508872896432877, 0.25609561800956726, 0.7418179512023926, 0.0019613259937614202]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 31/1194.6875 [01:40<1:00:59,  3.15s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END\tIN\tNL-HaNA_1.04.02_2480_0053.jpg\tbewesen, met afsmeking; van sijne dierbare genade;\t[9.449372555536684e-07, 1.37597213623053e-08, 0.9999984502792358, 5.828183589073888e-07]\n",
      "BEGIN\tIN\tNL-HaNA_1.04.02_1653_0085.jpg\tWatter op VEd:e Hoog agtb:; Eijs van 250 a 300000 \t[0.9998195767402649, 9.451647929381579e-05, 8.532209903933108e-05, 5.58678834750026e-07]\n",
      "BEGIN\tIN\tNL-HaNA_1.04.02_7532_0612.jpg\ten die vande generale Jaarlijxe; verpagtinge voor \t[0.9982746839523315, 0.0016700949054211378, 5.302402496454306e-05, 2.0991035398765234e-06]\n",
      "BEGIN\tIN\tNL-HaNA_1.04.02_3280_0505.jpg\tte rug gezonden waaren, en de overige; in 't hospi\t[0.9999629259109497, 1.1913843081856612e-05, 2.5062397980946116e-05, 6.872914326550017e-08]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 32/1194.6875 [01:41<1:01:21,  3.17s/batch]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import sys\n",
    "\n",
    "from torcheval.metrics import (\n",
    "    MulticlassAccuracy,\n",
    "    MulticlassF1Score,\n",
    "    MulticlassPrecision,\n",
    "    MulticlassRecall,\n",
    ")\n",
    "from tqdm import tqdm\n",
    "\n",
    "from document_segmentation.pagexml.datamodel.label import Label\n",
    "\n",
    "writer = csv.DictWriter(\n",
    "    sys.stdout,\n",
    "    fieldnames=(\"Predicted\", \"Actual\", \"Page ID\", \"Text\", \"Scores\"),\n",
    "    delimiter=\"\\t\",\n",
    ")\n",
    "\n",
    "writer.writeheader()\n",
    "\n",
    "accuracy = MulticlassAccuracy(num_classes=len(Label))\n",
    "precision = MulticlassPrecision(average=None, num_classes=len(Label))\n",
    "recall = MulticlassRecall(average=None, num_classes=len(Label))\n",
    "f1_score = MulticlassF1Score(average=None, num_classes=len(Label))\n",
    "\n",
    "for batch in tqdm(\n",
    "    test_data[:1000].batches(BATCH_SIZE),\n",
    "    total=len(test_data) / BATCH_SIZE,\n",
    "    unit=\"batch\",\n",
    "):\n",
    "    predicted = model(batch)\n",
    "    labels = batch.labels()\n",
    "\n",
    "    _labels = torch.Tensor([label.value - 1 for label in labels]).to(int)\n",
    "    accuracy.update(predicted, _labels)\n",
    "    precision.update(predicted, _labels)\n",
    "    recall.update(predicted, _labels)\n",
    "    f1_score.update(predicted, _labels)\n",
    "\n",
    "    for page, pred, label in zip(batch.pages, predicted, labels):\n",
    "        pred_label = Label(pred.argmax().item() + 1)\n",
    "        if pred_label != Label.IN or label != Label.IN:\n",
    "            writer.writerow(\n",
    "                {\n",
    "                    \"Predicted\": pred_label.name,\n",
    "                    \"Actual\": label.name,\n",
    "                    \"Page ID\": page.doc_id,\n",
    "                    \"Text\": page.text(delimiter=\"; \")[:50],\n",
    "                    \"Scores\": str(pred.tolist()),\n",
    "                }\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:tensor([[3]]) classes have zero instances in both the predictions and the ground truth labels. Precision is still logged as zero.\n",
      "WARNING:root:One or more NaNs identified, as no ground-truth instances of [3] have been seen. These have been converted to zero.\n",
      "WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric\tAverage\tBEGIN\tIN\tEND\tOUT\n",
      "MulticlassPrecision\tNone\t0.1379\t0.9989\t0.1562\t0.0000\n",
      "MulticlassRecall\tNone\t0.8000\t0.9475\t1.0000\t0.0000\n",
      "MulticlassF1Score\tNone\t0.2353\t0.9725\t0.2703\t0.0000\n",
      "Accuracy (micro average):\t0.9470\n"
     ]
    }
   ],
   "source": [
    "writer = csv.DictWriter(\n",
    "    sys.stdout,\n",
    "    fieldnames=[\"Metric\", \"Average\"] + [label.name for label in Label],\n",
    "    delimiter=\"\\t\",\n",
    ")\n",
    "writer.writeheader()\n",
    "\n",
    "for metric in (precision, recall, f1_score):\n",
    "    scores = {\n",
    "        label.name: f\"{score:.4f}\"\n",
    "        for label, score in zip(Label, metric.compute().tolist())\n",
    "    }\n",
    "    writer.writerow(\n",
    "        {\"Metric\": metric.__class__.__name__, \"Average\": str(metric.average)} | scores\n",
    "    )\n",
    "\n",
    "print(f\"Accuracy ({accuracy.average} average):\\t{accuracy.compute().item():.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
